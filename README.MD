В данном проекте реализован процесс обработки и добавления в БД датасета основной выгрузки, датасетов дополнительных выгрузок и процесс обработки и добавления датасетов дополнительных выгрузок по расписанию.

С целями и этапами проекта можно ознакомиться в презентации "DE presentation Slavkin.pdf".

Подробнее:
- обработка данных из csv-файлов;
- создание и заполнение локальной базы данных в PostgreSQL;
- обработка и добавление новых данных из json-файлов;
- создание пайплайна Airflow для обработки и добавления новых данных из json-файлов по расписанию.

Структура проекта:
main.py - главный модуль
preparation.py - модуль обработки основного сырого датасета
DDL.py - модуль создания и заполнения БД
add_extr_data.py - модуль обработки и добавления новых данных из json-файлов
fw_dag.py - DAG Airflow для обработки и добавления новых данных из json-файлов по расписанию

ВНИМАНИЕ!
В проекте использован файл ddl.ini, содержащий информацию для подключения базы данных и путь к папке с проектом. Его необходимо заполнить для корректной работы кода, а также скопировать вместе с DAG'ом в папку с Airflow (/dags).

Данный проект полностью или частично может быть встроен в более крупный проект обработки данных с возможностью масштабирования и дальнейшей автоматизации. 
